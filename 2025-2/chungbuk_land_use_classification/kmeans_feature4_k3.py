# -*- coding: utf-8 -*-
"""
ì¶©ë¶ í† ì§€ì´ìš© êµ°ì§‘ ë¶„ì„ (KMeans + PCA + Softmax í™•ë¥ )
 - ëŒ€ìƒ: 2015~2025ë…„ ì „ì²´, (ì—°ë„, í–‰ì •êµ¬ì—­) ë‹¨ìœ„
 - íŠ¹ì§•: ì„ì•¼/ë†ê²½ì§€/ëŒ€ì§€/ê³µì¥ìš©ì§€ ë¹„ìœ¨ (4ì°¨ì›)
 - êµ°ì§‘: KMeans(k=3)
 - ì‹œê°í™”: PCA(2D) + í´ëŸ¬ìŠ¤í„° ìƒ‰ìƒ
 - ê° ìœ í˜•(ë„ì‹œ/ì‚°ì—…í˜•, ë†ì—…/ì‚°ë¦¼í˜•, ê· í˜•í˜•)ì— ëŒ€í•œ softmax í™•ë¥  ê³„ì‚°
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

# ===== í•œê¸€ í°íŠ¸ ì„¤ì • =====
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# (ì„ íƒ) KMeans ë©”ëª¨ë¦¬ ê²½ê³  ì™„í™”
os.environ["OMP_NUM_THREADS"] = "1"

# ===== 1) ë°ì´í„° ë¡œë“œ =====
base_dir = r"data"
detail_csv_path = os.path.join(base_dir, "chungbuk_landuse_composition_2015_2025.csv")

df = pd.read_csv(detail_csv_path, encoding="cp949")

# 'ì¶©ì²­ë¶ë„ í•©ê³„' ì œì™¸
df = df[df["í† ì§€ì†Œì¬ëª…"] != "ì¶©ì²­ë¶ë„ í•©ê³„"].copy().reset_index(drop=True)

col_region  = "í† ì§€ì†Œì¬ëª…"
col_year    = "year"
col_forest  = "ì„ì•¼ ë©´ì (ã¡)"
col_agri    = "ë†ê²½ì§€ ë©´ì (ã¡)"
col_dae     = "ëŒ€ ë©´ì (ã¡)"
col_factory = "ê³µì¥ìš©ì§€ ë©´ì (ã¡)"

df[col_year] = df[col_year].astype(int)

# ===== 2) 2015~2025 ì „ì²´ì— ëŒ€í•´ ë¹„ìœ¨ ê³„ì‚° =====

col_total = "í•©ê³„ ë©´ì (ã¡)"

denom = df[col_total]  # ì§€ì—­Â·ì—°ë„ë³„ ì „ì²´ ë©´ì 

#denom = df[col_forest] + df[col_agri] + df[col_dae] + df[col_factory]

df["ì„ì•¼ ë¹„ìœ¨"]      = df[col_forest]  / denom
df["ë†ê²½ì§€ ë¹„ìœ¨"]    = df[col_agri]    / denom
df["ëŒ€ì§€ ë¹„ìœ¨"]      = df[col_dae]     / denom
df["ê³µì¥ìš©ì§€ ë¹„ìœ¨"]  = df[col_factory] / denom

print("ì „ì²´ í–‰ ìˆ˜:", len(df))
print(df[[col_year, col_region, "ì„ì•¼ ë¹„ìœ¨", "ë†ê²½ì§€ ë¹„ìœ¨", "ëŒ€ì§€ ë¹„ìœ¨", "ê³µì¥ìš©ì§€ ë¹„ìœ¨"]].head())

# ===== 3) KMeans êµ°ì§‘ (k=3) â€“ 2015~2025 ì „ì²´ =====
feature_cols = ["ì„ì•¼ ë¹„ìœ¨", "ë†ê²½ì§€ ë¹„ìœ¨", "ëŒ€ì§€ ë¹„ìœ¨", "ê³µì¥ìš©ì§€ ë¹„ìœ¨"]
X = df[feature_cols].values

# ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# KMeans
kmeans = KMeans(n_clusters=3, random_state=0, n_init=50)
clusters = kmeans.fit_predict(X_scaled)

df["cluster"] = clusters

# í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬(centroid)ì„ ì›ë˜ ë¹„ìœ¨ ìŠ¤ì¼€ì¼ë¡œ ë³µì›
centers_scaled = kmeans.cluster_centers_
centers = scaler.inverse_transform(centers_scaled)

centers_df = pd.DataFrame(centers, columns=feature_cols)
centers_df["cluster"] = range(3)

# U, G ì§€í‘œ ê³„ì‚°
centers_df["U_ë„ì‹œì‚°ì—…"] = centers_df["ëŒ€ì§€ ë¹„ìœ¨"] + centers_df["ê³µì¥ìš©ì§€ ë¹„ìœ¨"]
centers_df["G_ë†ì—…ì‚°ë¦¼"] = centers_df["ì„ì•¼ ë¹„ìœ¨"] + centers_df["ë†ê²½ì§€ ë¹„ìœ¨"]

print("\n=== (2015~2025 ì „ì²´ ê¸°ì¤€) í´ëŸ¬ìŠ¤í„°ë³„ í‰ê·  ë¹„ìœ¨ ===")
print(centers_df)

# ===== 4) í´ëŸ¬ìŠ¤í„° ë¼ë²¨ë§ (ë„ì‹œ/ì‚°ì—…í˜•, ë†ì—…/ì‚°ë¦¼í˜•, ê· í˜•í˜•) =====
idx_urban = centers_df["U_ë„ì‹œì‚°ì—…"].idxmax()
cluster_urban = int(centers_df.loc[idx_urban, "cluster"])

idx_agri  = centers_df["G_ë†ì—…ì‚°ë¦¼"].idxmax()
cluster_agri = int(centers_df.loc[idx_agri, "cluster"])

all_clusters = set(centers_df["cluster"].tolist())
cluster_balanced = list(all_clusters - {cluster_urban, cluster_agri})[0]

cluster_label_map = {
    cluster_urban:    "ë„ì‹œ/ì‚°ì—…í˜•",
    cluster_agri:     "ë†ì—…/ì‚°ë¦¼í˜•",
    cluster_balanced: "ê· í˜•í˜•",
}

print("\ní´ëŸ¬ìŠ¤í„° ë¼ë²¨ ë§¤í•‘:", cluster_label_map)

df["ìœ í˜•"] = df["cluster"].map(cluster_label_map)

# =====================================================================
# 4-1) Softmax ê¸°ë°˜ ìœ í˜•ë³„ í™•ë¥  ê³„ì‚°
#  - KMeansì˜ ê° í¬ì¸íŠ¸-ì„¼í„° ê±°ë¦¬(dist)ë¥¼ ì´ìš©í•´ì„œ
#    softmax( -ê±°ë¦¬ ) ë¡œ 3ê°œ í´ëŸ¬ìŠ¤í„°ì— ëŒ€í•œ í™•ë¥ ì„ ê³„ì‚°
#  - ê·¸ í›„, clusterâ†’ìœ í˜• ë§¤í•‘ì„ ì´ìš©í•´
#    P_ë„ì‹œì‚°ì—…í˜•, P_ë†ì—…ì‚°ë¦¼í˜•, P_ê· í˜•í˜• ì—´ ì¶”ê°€
# =====================================================================

# (1) ê° ìƒ˜í”Œì˜ í´ëŸ¬ìŠ¤í„°ê¹Œì§€ì˜ ê±°ë¦¬ í–‰ë ¬ (N x 3)
distances = kmeans.transform(X_scaled)   # ìœ í´ë¦¬ë“œ ê±°ë¦¬

# (2) softmax ê³„ì‚° í•¨ìˆ˜
def softmax_neg_dist(d):
    # d: shape (3,) â€“ ê° í´ëŸ¬ìŠ¤í„°ê¹Œì§€ì˜ ê±°ë¦¬
    # score = -d  â†’ ê°€ê¹Œìš¸ìˆ˜ë¡ scoreê°€ ì»¤ì§
    s = -d
    s = s - np.max(s)   # overflow ë°©ì§€ìš©
    exp_s = np.exp(s)
    return exp_s / np.sum(exp_s)

# (3) ëª¨ë“  ìƒ˜í”Œì— ëŒ€í•´ softmax í™•ë¥  ê³„ì‚°
probs = np.apply_along_axis(softmax_neg_dist, 1, distances)  # shape (N, 3)

# (4) cluster ì¸ë±ìŠ¤ â†’ ìœ í˜• ì´ë¦„ ì—­ë§¤í•‘
type_to_cluster = {v: k for k, v in cluster_label_map.items()}

idx_u = type_to_cluster["ë„ì‹œ/ì‚°ì—…í˜•"]
idx_g = type_to_cluster["ë†ì—…/ì‚°ë¦¼í˜•"]
idx_b = type_to_cluster["ê· í˜•í˜•"]

# (5) ìœ í˜•ë³„ softmax í™•ë¥  ì»¬ëŸ¼ ì¶”ê°€ (0~1 ì‚¬ì´ ê°’)
df["P_ë„ì‹œì‚°ì—…í˜•"] = probs[:, idx_u]
df["P_ë†ì—…ì‚°ë¦¼í˜•"] = probs[:, idx_g]
df["P_ê· í˜•í˜•"]     = probs[:, idx_b]

# (ì„ íƒ) 100%ë¡œ ë³´ê³  ì‹¶ìœ¼ë©´ ì•„ë˜ì²˜ëŸ¼ ê³±í•´ì„œ ìƒˆ ì»¬ëŸ¼ì„ ë” ë§Œë“¤ ìˆ˜ë„ ìˆìŒ
# df["P_ë„ì‹œì‚°ì—…í˜•(%)"] = df["P_ë„ì‹œì‚°ì—…í˜•"] * 100
# df["P_ë†ì—…ì‚°ë¦¼í˜•(%)"] = df["P_ë†ì—…ì‚°ë¦¼í˜•"] * 100
# df["P_ê· í˜•í˜•(%)"]     = df["P_ê· í˜•í˜•"] * 100

# =====================================================================
# 5) PCA 2D ì‹œê°í™” (2015~2025 ì „ì²´, ë¼ë²¨ì€ 2025ë…„ë§Œ)
# =====================================================================
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

df["PC1"] = X_pca[:, 0]
df["PC2"] = X_pca[:, 1]

plt.figure(figsize=(9, 7))

type_colors = {
    "ë„ì‹œ/ì‚°ì—…í˜•": "#EA9358",  # red-ish
    "ë†ì—…/ì‚°ë¦¼í˜•": "#75CD97",  # green-ish
    "ê· í˜•í˜•":     "#589AEA",  # blue-ish
}

for t, sub in df.groupby("ìœ í˜•"):
    # ì ì€ ëª¨ë“  ì—°ë„(2015~2025)ë¥¼ ê·¸ë¦¼
    plt.scatter(
        sub["PC1"],
        sub["PC2"],
        label=t,
        color=type_colors.get(t, "gray"),
        alpha=0.9,
        s=60,
    )
    # ğŸ”¹ í…ìŠ¤íŠ¸ëŠ” 2025ë…„ ë°ì´í„°ì— ëŒ€í•´ì„œë§Œ, ì—°ë„ ì—†ì´ ì§€ì—­ëª…ë§Œ í‘œì‹œ
    sub_2025 = sub[sub[col_year] == 2025]
    for _, row in sub_2025.iterrows():
        label_txt = row[col_region]
        plt.text(
            row["PC1"] + 0.02,
            row["PC2"] + 0.02,
            label_txt,
            fontsize=8
        )

plt.axhline(0, color="gray", linewidth=0.5)
plt.axvline(0, color="gray", linewidth=0.5)
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.title("ì¶©ë¶ í† ì§€ì´ìš© êµ°ì§‘ (KMeans, 2015~2025ë…„, ì„ì•¼/ë†ê²½ì§€/ëŒ€ì§€/ê³µì¥ ë¹„ìœ¨)")
plt.legend(title="ì§€ì—­ ìœ í˜•")
plt.tight_layout()

pca_outfile = os.path.join(base_dir, "clusters_feature4_k3.png")
plt.savefig(pca_outfile, dpi=200)
plt.close()

print("\nPCA ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥:", pca_outfile)

# =====================================================================
# 6) ê²°ê³¼ CSV ì €ì¥ (ëª¨ë“  ì—°ë„ + softmax í™•ë¥ )
# =====================================================================
out_csv = os.path.join(base_dir, "clusters_feature4_k3_softmax.csv")
save_cols = [
    col_year, col_region,
    col_forest, col_agri, col_dae, col_factory,
    "ì„ì•¼ ë¹„ìœ¨", "ë†ê²½ì§€ ë¹„ìœ¨", "ëŒ€ì§€ ë¹„ìœ¨", "ê³µì¥ìš©ì§€ ë¹„ìœ¨",
    "cluster", "ìœ í˜•",
    "P_ë„ì‹œì‚°ì—…í˜•", "P_ë†ì—…ì‚°ë¦¼í˜•", "P_ê· í˜•í˜•",
    "PC1", "PC2",
]
df[save_cols].to_csv(out_csv, index=False, encoding="cp949")
print("êµ°ì§‘ + Softmax ê²°ê³¼ CSV ì €ì¥:", out_csv)

print("\n=== êµ°ì§‘ ë¶„ì„(KMeans+PCA+Softmax, 2015~2025 ì „ì²´) ì™„ë£Œ ===")

loadings = pd.DataFrame(
    pca.components_,
    columns=feature_cols,
    index=["PC1", "PC2"]
)
print("\n=== PCA ì„±ë¶„ ê³„ìˆ˜(Loadings) ===")
print(loadings)

print("\n=== ê° PCê°€ ì„¤ëª…í•˜ëŠ” ë¶„ì‚° ë¹„ìœ¨ ===")
print(pd.Series(pca.explained_variance_ratio_, index=["PC1", "PC2"]))



