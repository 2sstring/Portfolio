# -*- coding: utf-8 -*-
"""
ì¶©ë¶ í† ì§€ì´ìš© êµ°ì§‘ ë¶„ì„ (KMeans + PCA + Softmax í™•ë¥ )

- ëŒ€ìƒ: chungbuk_data_2015~2025 (ì—°ë„ë³„ CSV, ì—°ë§ ê¸°ì¤€)
- íŠ¹ì§•:
    Â· ëª¨ë“  '... ë©´ì (ã¡)' ë¹„ìœ¨
    Â· ì¸êµ¬ë°€ë„(pop_density)
- êµ°ì§‘: KMeans(k=3)  â€» ì „ì²´ ì—°ë„ í†µí•© 1íšŒ
- ì‹œê°í™”: PCA(2D)
- ì¶”ê°€: Softmax ê¸°ë°˜ ìœ í˜•ë³„ í™•ë¥ 
"""

import os
import glob
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

# =========================================================
# 0. ê¸°ë³¸ ì„¤ì •
# =========================================================
plt.rcParams["font.family"] = "Malgun Gothic"
plt.rcParams["axes.unicode_minus"] = False
os.environ["OMP_NUM_THREADS"] = "1"

base_dir = r"C:/Users/leebi/OneDrive/ë°”íƒ• í™”ë©´/team_project"
landuse_pattern = os.path.join(base_dir, "chungbuk_data_*.csv")
pop_xlsx_path = os.path.join(base_dir, "chungbuk_population.xlsx")

col_region = "í† ì§€ì†Œì¬ëª…"
col_year   = "year"
col_total  = "í•©ê³„ ë©´ì (ã¡)"

# =========================================================
# 1. í† ì§€ì´ìš© CSV ì „ì²´ ë¡œë“œ (ì—°ë„ ìë™ ì¶”ì¶œ)
# =========================================================
landuse_files = sorted(glob.glob(landuse_pattern))
if not landuse_files:
    raise FileNotFoundError("í† ì§€ì´ìš© CSV íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

df_list = []

for path in landuse_files:
    name = os.path.basename(path)

    # ğŸ”¹ ì •ê·œì‹ìœ¼ë¡œ ì—°ë„ ì¶”ì¶œ (2015~2025 ì•ˆì „)
    m = re.search(r"(20\d{2})", name)
    if not m:
        print(f"âš  ì—°ë„ ì¶”ì¶œ ì‹¤íŒ¨, ìŠ¤í‚µ: {name}")
        continue
    year = int(m.group(1))

    # ì¸ì½”ë”© ì•ˆì „ ì²˜ë¦¬
    try:
        tmp = pd.read_csv(path, encoding="utf-8-sig")
    except UnicodeDecodeError:
        try:
            tmp = pd.read_csv(path, encoding="cp949")
        except UnicodeDecodeError:
            tmp = pd.read_csv(path, encoding="euc-kr")

    tmp[col_year] = year
    df_list.append(tmp)

df = pd.concat(df_list, ignore_index=True)

print("ğŸ“Œ ì—°ë„ ëª©ë¡:", sorted(df[col_year].unique()))
print("ğŸ“Œ ì „ì²´ ë°ì´í„° í¬ê¸°:", df.shape)

# =========================================================
# 2. ìˆ«ì ì»¬ëŸ¼ ì •ë¦¬
# =========================================================
num_cols = [c for c in df.columns if c != col_region]

for c in num_cols:
    df[c] = (
        df[c]
        .astype(str)
        .str.replace(",", "", regex=False)
        .str.strip()
    )
    df[c] = pd.to_numeric(df[c], errors="coerce")

# =========================================================
# 3. ì¸êµ¬ ë°ì´í„° ë³‘í•©
# =========================================================
pop_raw = pd.read_excel(pop_xlsx_path)

pop_long = pop_raw.melt(
    id_vars=["ì—°ë„"],
    var_name="year",
    value_name="ì¸êµ¬"
)
pop_long["year"] = pop_long["year"].astype(int)
pop_long = pop_long.rename(columns={"ì—°ë„": col_region})

df = df.merge(pop_long, on=[col_region, col_year], how="left")

# =========================================================
# 4. ëª¨ë“  ë©´ì  ë¹„ìœ¨ ê³„ì‚° (ë¶„ëª¨ = í•©ê³„ ë©´ì )
# =========================================================
area_cols = [c for c in df.columns if c.endswith("ë©´ì (ã¡)") and c != col_total]

denom = df[col_total].replace(0, np.nan)

ratio_cols = []
for c in area_cols:
    new_c = c.replace(" ë©´ì (ã¡)", " ë¹„ìœ¨")
    df[new_c] = df[c] / denom
    ratio_cols.append(new_c)

# =========================================================
# 5. ì¸êµ¬ë°€ë„ ê³„ì‚°
# =========================================================
df["pop_density"] = df["ì¸êµ¬"] / (df[col_total] / 1_000_000)

# =========================================================
# 6. êµ°ì§‘ìš© ë°ì´í„° ì •ë¦¬ (NaN í–‰ ì œê±°)
# =========================================================
feature_cols = ratio_cols + ["pop_density"]

nan_mask = df[feature_cols].isna().any(axis=1)
print("âš  NaN í¬í•¨ í–‰ ì œê±°:", nan_mask.sum())

df = df[~nan_mask].copy()

X = df[feature_cols].values

# =========================================================
# 7. ìŠ¤ì¼€ì¼ë§ + KMeans (1íšŒ)
# =========================================================
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

kmeans = KMeans(n_clusters=3, random_state=0, n_init=50)
df["cluster"] = kmeans.fit_predict(X_scaled)

# =========================================================
# 8. í´ëŸ¬ìŠ¤í„° ìœ í˜• ì •ì˜ (U/G ì§€í‘œ)
# =========================================================
centers = scaler.inverse_transform(kmeans.cluster_centers_)
centers_df = pd.DataFrame(centers, columns=feature_cols)
centers_df["cluster"] = range(3)

urban_cols = [c for c in centers_df.columns if any(
    k in c for k in ["ëŒ€ ë¹„ìœ¨", "ê³µì¥", "ì£¼ì°¨ì¥", "ì£¼ìœ ì†Œ", "ì°½ê³ ", "ë„ë¡œ", "ì² ë„"]
)]

agri_cols = [c for c in centers_df.columns if any(
    k in c for k in ["ì„ì•¼", "ì „ ë¹„ìœ¨", "ë‹µ ë¹„ìœ¨", "ê³¼ìˆ˜ì›", "ëª©ì¥"]
)]

centers_df["U"] = centers_df[urban_cols].sum(axis=1)
centers_df["G"] = centers_df[agri_cols].sum(axis=1)

cluster_urban = centers_df.loc[centers_df["U"].idxmax(), "cluster"]
cluster_agri  = centers_df.loc[centers_df["G"].idxmax(), "cluster"]
cluster_bal   = list(set(range(3)) - {cluster_urban, cluster_agri})[0]

label_map = {
    cluster_urban: "ë„ì‹œ/ì‚°ì—…í˜•",
    cluster_agri: "ë†ì—…/ì‚°ë¦¼í˜•",
    cluster_bal: "ê· í˜•í˜•"
}

df["ìœ í˜•"] = df["cluster"].map(label_map)

# =========================================================
# 9. Softmax í™•ë¥  ê³„ì‚°
# =========================================================
dist = kmeans.transform(X_scaled)

def softmax_neg(d):
    s = -d
    s -= np.max(s)
    e = np.exp(s)
    return e / e.sum()

probs = np.apply_along_axis(softmax_neg, 1, dist)

rev = {v: k for k, v in label_map.items()}

df["P_ë„ì‹œì‚°ì—…í˜•"] = probs[:, rev["ë„ì‹œ/ì‚°ì—…í˜•"]]
df["P_ë†ì—…ì‚°ë¦¼í˜•"] = probs[:, rev["ë†ì—…/ì‚°ë¦¼í˜•"]]
df["P_ê· í˜•í˜•"]     = probs[:, rev["ê· í˜•í˜•"]]

# =========================================================
# 10. PCA ì‹œê°í™”
# =========================================================
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

df["PC1"] = X_pca[:, 0]
df["PC2"] = X_pca[:, 1]

plt.figure(figsize=(9, 7))
colors = {
    "ë„ì‹œ/ì‚°ì—…í˜•": "#EA9358",
    "ë†ì—…/ì‚°ë¦¼í˜•": "#75CD97",
    "ê· í˜•í˜•": "#589AEA",
}

for t, sub in df.groupby("ìœ í˜•"):
    plt.scatter(sub["PC1"], sub["PC2"], label=t, s=60, alpha=0.9, color=colors[t])

latest = df[col_year].max()
for _, r in df[df[col_year] == latest].iterrows():
    plt.text(r["PC1"]+0.02, r["PC2"]+0.02, r[col_region], fontsize=8)

plt.legend()
plt.title(f"ì¶©ë¶ í† ì§€ì´ìš© êµ°ì§‘ ({df[col_year].min()}~{latest})")
plt.tight_layout()

plt.savefig(os.path.join(base_dir, "cluster_pca_all_area_ratio_pop.png"), dpi=200)
plt.close()

# ===== ì €ì¥ ì „ year ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸/ê°•ì œ =====
print("ì €ì¥ ì§ì „ ì»¬ëŸ¼:", df.columns.tolist()[:20], "...")  # ì¼ë¶€ë§Œ ë³´ê¸°
if col_year not in df.columns:
    raise RuntimeError(f"âŒ '{col_year}' ì»¬ëŸ¼ì´ dfì— ì—†ìŠµë‹ˆë‹¤. (ì—°ë„ ë¶€ì—¬ ë‹¨ê³„ê°€ ëˆ„ë½ë¨)")

# yearë¥¼ ì²« ì—´ë¡œ ë³´ë‚´ê¸°(ì—‘ì…€ì—ì„œ ì•ˆ ë³´ì´ëŠ” ë¬¸ì œ ë°©ì§€)
df = df[[col_year] + [c for c in df.columns if c != col_year]]


# =========================================================
# 11. ê²°ê³¼ ì €ì¥
# =========================================================
out_csv = os.path.join(base_dir, "chungbuk_clusters_all_area_ratio_softmax_pop.csv")
df.to_csv(out_csv, index=False, encoding="cp949")

print("âœ… ë¶„ì„ ì™„ë£Œ")
print("ğŸ“ ê²°ê³¼ CSV:", out_csv)
